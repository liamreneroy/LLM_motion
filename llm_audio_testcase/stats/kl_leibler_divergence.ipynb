{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for KL Leibler Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/liamroy/Documents/Studies/Monash_31194990/PHD/Studies/Study_03/LLM_motion/llm_audio_testcase/stats'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    return data / np.sum(data)\n",
    "\n",
    "def kl_divergence(P, Q):\n",
    "    return np.sum(P * np.log(P / Q))\n",
    "\n",
    "def jensen_shannon_distance(P, Q):\n",
    "    P = normalize(P)\n",
    "    Q = normalize(Q)\n",
    "    \n",
    "    M = 0.5 * (P + Q)\n",
    "    \n",
    "    kl_p_m = kl_divergence(P, M)\n",
    "    kl_q_m = kl_divergence(Q, M)\n",
    "    \n",
    "    jsd = 0.5 * kl_p_m + 0.5 * kl_q_m\n",
    "    \n",
    "    return np.sqrt(jsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@ Kullback–Leibler Divergence For State: stuck @@@@@@@@@@@@@@@\n",
      "\n",
      "\n",
      " >>> KL Divergence for the state stuck is: 0.661\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@ Kullback–Leibler Divergence For State: accomplished @@@@@@@@@@@@@@@\n",
      "\n",
      "\n",
      " >>> KL Divergence for the state accomplished is: 1.284\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@ Kullback–Leibler Divergence For State: progressing @@@@@@@@@@@@@@@\n",
      "\n",
      "\n",
      " >>> KL Divergence for the state progressing is: 20.168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conditions = [\"llm\", \"human\"]\n",
    "states = [\"stuck\", \"accomplished\", \"progressing\"]\n",
    "\n",
    "for state in states:\n",
    "    print(f\"\\n\\n@@@@@@@@@@@@@@@ Kullback–Leibler Divergence For State: {state} @@@@@@@@@@@@@@@\\n\")\n",
    "\n",
    "    # FIRST DO LLM COND:\n",
    "    # Load the data from the Excel file, specifying the sheet name\n",
    "    llm_file_path = './../llm_audio_rawdata.xlsx'  # Replace with your file path\n",
    "    llm_data = pd.read_excel(llm_file_path,sheet_name='llm_' + state + '_00', usecols=\"D:F\", nrows=80)\n",
    "\n",
    "    mapping = {'A': 0, 'B': 1, 'C': 2}\n",
    "    llm_data = llm_data.replace(mapping).infer_objects()\n",
    "\n",
    "    # Convert data to numeric values, coercing errors (e.g., empty cells or non-numeric text will become NaN)\n",
    "    llm_data = llm_data.apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Ensure the data values are between 0 and 2 as required\n",
    "    assert llm_data.values.max() <= 2 and llm_data.values.min() >= 0, \"Values out of range (0, 1, 2)\"\n",
    "\n",
    "    # Initialize a 3x3x3 numpy array to hold the histogram counts\n",
    "    llm_data_histogram = np.zeros((3, 3, 3), dtype=int)\n",
    "\n",
    "    # Iterate through each row in the DataFrame and bin the data\n",
    "    for row in llm_data.itertuples(index=False):\n",
    "        x, y, z = row  # Unpack the three-vector (each value will be 0, 1, or 2)\n",
    "        llm_data_histogram[x, y, z] += 1\n",
    "\n",
    "    # print(f\"LLM DATA |3x3x3 Histogram Matrix for {state}:\")\n",
    "    # print(llm_data_histogram)\n",
    "\n",
    "\n",
    "    # THEN DO HUMAN COND:\n",
    "    # Load the data from the Excel file, specifying the sheet name\n",
    "    human_file_path = './../llm_audio_rawdata.xlsx'  # Replace with your file path\n",
    "    human_data = pd.read_excel(human_file_path,sheet_name='human_' + state + '_00', usecols=\"D:F\", nrows=24)\n",
    "\n",
    "    mapping = {'A': 0, 'B': 1, 'C': 2}\n",
    "    human_data = human_data.replace(mapping).infer_objects()\n",
    "\n",
    "    # Convert data to numeric values, coercing errors (e.g., empty cells or non-numeric text will become NaN)\n",
    "    human_data = human_data.apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Ensure the data values are between 0 and 2 as required\n",
    "    assert human_data.values.max() <= 2 and human_data.values.min() >= 0, \"Values out of range (0, 1, 2)\"\n",
    "\n",
    "    # Initialize a 3x3x3 numpy array to hold the histogram counts\n",
    "    human_data_histogram = np.zeros((3, 3, 3), dtype=int)\n",
    "\n",
    "    # Iterate through each row in the DataFrame and bin the data\n",
    "    for row in human_data.itertuples(index=False):\n",
    "        x, y, z = row  # Unpack the three-vector (each value will be 0, 1, or 2)\n",
    "        human_data_histogram[x, y, z] += 1\n",
    "\n",
    "    # print(f\"HUMAN DATA | 3x3x3 Histogram Matrix for {state}:\")\n",
    "    # print(human_data_histogram)\n",
    "\n",
    "\n",
    "    # Then, flatten each 3x3x3 matrix into a 1D vector of length 27\n",
    "    llm_vector = llm_data_histogram.flatten()\n",
    "    human_vector = human_data_histogram.flatten()\n",
    "\n",
    "    # Then, convert to probability distributions. Since KL Divergence operates on \n",
    "    # probability distributions, normalize each vector so that the sum of its elements is 1\n",
    "    llm_prob = normalize(llm_vector) \n",
    "    human_prob = normalize(human_vector)\n",
    "\n",
    "    # Next, add smoothing. Since some bins in B_prob are zero, add a small \n",
    "    # smoothing value (1e−9) to avoid division by zero in the KL Divergence calculation\n",
    "    llm_prob_smooth = np.where(llm_prob == 0, 1e-9, llm_prob)\n",
    "    human_prob_smooth = np.where(human_prob == 0, 1e-9, human_prob)  \n",
    "\n",
    "    # Finally, compute KL Divergence using the formula:KL_divergence = np.sum(seriesA * np.log(seriesA / seriesB))\n",
    "    # This quantifies how how much Series B diverges from Series A, capturing the \"distance\" between the two distributions. \n",
    "    # Lower values indicate greater similarity, meaning Series A is more contained within Series B.\n",
    "\n",
    "    KL_divergence = kl_divergence(llm_prob_smooth, human_prob_smooth)\n",
    " \n",
    "    print(f\"\\n >>> KL Divergence for the state {state} is: {KL_divergence:.3f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now do Jensen-Shannon Distance (JSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "@@@ Jensen-Shannon Distance Betweem LLM-Generated Audio State 'stuck' and Human After RL Learning @@@\n",
      "\n",
      ">>> Jensen-Shannon Distance for the state stuck is: 0.444\n",
      "\n",
      "\n",
      "\n",
      "@@@ Jensen-Shannon Distance Betweem LLM-Generated Audio State 'accomplished' and Human After RL Learning @@@\n",
      "\n",
      ">>> Jensen-Shannon Distance for the state accomplished is: 0.553\n",
      "\n",
      "\n",
      "\n",
      "@@@ Jensen-Shannon Distance Betweem LLM-Generated Audio State 'progressing' and Human After RL Learning @@@\n",
      "\n",
      ">>> Jensen-Shannon Distance for the state progressing is: 0.819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "\n",
    "    # FIRST DO LLM COND:\n",
    "    # Load the data from the Excel file, specifying the sheet name\n",
    "    llm_file_path = './../llm_audio_rawdata.xlsx'  # Replace with your file path\n",
    "    llm_data = pd.read_excel(llm_file_path,sheet_name='llm_' + state + '_00', usecols=\"D:F\", nrows=80)\n",
    "\n",
    "    mapping = {'A': 0, 'B': 1, 'C': 2}\n",
    "    llm_data = llm_data.replace(mapping).infer_objects()\n",
    "\n",
    "    # Convert data to numeric values, coercing errors (e.g., empty cells or non-numeric text will become NaN)\n",
    "    llm_data = llm_data.apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Ensure the data values are between 0 and 2 as required\n",
    "    assert llm_data.values.max() <= 2 and llm_data.values.min() >= 0, \"Values out of range (0, 1, 2)\"\n",
    "\n",
    "    # Initialize a 3x3x3 numpy array to hold the histogram counts\n",
    "    llm_data_histogram = np.zeros((3, 3, 3), dtype=int)\n",
    "\n",
    "    # Iterate through each row in the DataFrame and bin the data\n",
    "    for row in llm_data.itertuples(index=False):\n",
    "        x, y, z = row  # Unpack the three-vector (each value will be 0, 1, or 2)\n",
    "        llm_data_histogram[x, y, z] += 1\n",
    "\n",
    "    # THEN DO HUMAN COND:\n",
    "    # Load the data from the Excel file, specifying the sheet name\n",
    "    human_file_path = './../llm_audio_rawdata.xlsx'  # Replace with your file path\n",
    "    human_data = pd.read_excel(human_file_path,sheet_name='human_' + state + '_00', usecols=\"D:F\", nrows=24)\n",
    "\n",
    "    mapping = {'A': 0, 'B': 1, 'C': 2}\n",
    "    human_data = human_data.replace(mapping).infer_objects()\n",
    "\n",
    "    # Convert data to numeric values, coercing errors (e.g., empty cells or non-numeric text will become NaN)\n",
    "    human_data = human_data.apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Ensure the data values are between 0 and 2 as required\n",
    "    assert human_data.values.max() <= 2 and human_data.values.min() >= 0, \"Values out of range (0, 1, 2)\"\n",
    "\n",
    "    # Initialize a 3x3x3 numpy array to hold the histogram counts\n",
    "    human_data_histogram = np.zeros((3, 3, 3), dtype=int)\n",
    "\n",
    "    # Iterate through each row in the DataFrame and bin the data\n",
    "    for row in human_data.itertuples(index=False):\n",
    "        x, y, z = row  # Unpack the three-vector (each value will be 0, 1, or 2)\n",
    "        human_data_histogram[x, y, z] += 1\n",
    "\n",
    "\n",
    "    # PRINT SANITY CHECK\n",
    "    # print(\"llm_data_histogram:\\n\", llm_data_histogram)\n",
    "    # print(\"human_data_histogram:\\n\", human_data_histogram)\n",
    "\n",
    "\n",
    "    # Then, flatten each 3x3x3 matrix into a 1D vector of length 27\n",
    "    llm_vector = llm_data_histogram.flatten()\n",
    "    human_vector = human_data_histogram.flatten()\n",
    "\n",
    "    # Then, convert to probability distributions. Since KL Divergence operates on \n",
    "    # probability distributions, normalize each vector so that the sum of its elements is 1\n",
    "    llm_prob = normalize(llm_vector) \n",
    "    human_prob = normalize(human_vector)\n",
    "\n",
    "    # Next, add smoothing. Since some bins in B_prob are zero, add a small \n",
    "    # smoothing value (1e−9) to avoid division by zero in the KL Divergence calculation\n",
    "    llm_prob_smooth = np.where(llm_prob == 0, 1e-9, llm_prob)\n",
    "    human_prob_smooth = np.where(human_prob == 0, 1e-9, human_prob)  \n",
    "    \n",
    "    print(f\"\\n\\n@@@ Jensen-Shannon Distance Betweem LLM-Generated Audio State '{state}' and Human After RL Learning @@@\\n\")\n",
    "\n",
    "    JS_distance = jensen_shannon_distance(llm_prob_smooth, human_prob_smooth)\n",
    "    print(f\">>> Jensen-Shannon Distance for the state {state} is: {JS_distance:.3f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, Jensen-Shannon Distance for LLM-Audio and Uniform Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "@@@ Jensen-Shannon Distance Betweem LLM-Generated Audio State 'stuck' and Uniform Distribution @@@\n",
      "\n",
      ">>> Jensen-Shannon Distance for the state stuck is: 0.833\n",
      "\n",
      "\n",
      "\n",
      "@@@ Jensen-Shannon Distance Betweem LLM-Generated Audio State 'accomplished' and Uniform Distribution @@@\n",
      "\n",
      ">>> Jensen-Shannon Distance for the state accomplished is: 0.833\n",
      "\n",
      "\n",
      "\n",
      "@@@ Jensen-Shannon Distance Betweem LLM-Generated Audio State 'progressing' and Uniform Distribution @@@\n",
      "\n",
      ">>> Jensen-Shannon Distance for the state progressing is: 0.819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "\n",
    "    # FIRST DO LLM COND:\n",
    "    # Load the data from the Excel file, specifying the sheet name\n",
    "    llm_file_path = './../llm_audio_rawdata.xlsx'  # Replace with your file path\n",
    "    llm_data = pd.read_excel(llm_file_path,sheet_name='llm_' + state + '_00', usecols=\"D:F\", nrows=80)\n",
    "\n",
    "    mapping = {'A': 0, 'B': 1, 'C': 2}\n",
    "    llm_data = llm_data.replace(mapping).infer_objects()\n",
    "\n",
    "    # Convert data to numeric values, coercing errors (e.g., empty cells or non-numeric text will become NaN)\n",
    "    llm_data = llm_data.apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Ensure the data values are between 0 and 2 as required\n",
    "    assert llm_data.values.max() <= 2 and llm_data.values.min() >= 0, \"Values out of range (0, 1, 2)\"\n",
    "\n",
    "    # Initialize a 3x3x3 numpy array to hold the histogram counts\n",
    "    llm_data_histogram = np.zeros((3, 3, 3), dtype=int)\n",
    "\n",
    "    # Iterate through each row in the DataFrame and bin the data\n",
    "    for row in llm_data.itertuples(index=False):\n",
    "        x, y, z = row  # Unpack the three-vector (each value will be 0, 1, or 2)\n",
    "        llm_data_histogram[x, y, z] += 1\n",
    "\n",
    "    # THEN CREATE A UNIFORM DISTRIBUTION:\n",
    "    # Load the data from the Excel file, specifying the sheet name\n",
    "    uniform_histogram = np.ones((3, 3, 3), dtype=int)\n",
    "        \n",
    "\n",
    "    # PRINT SANITY CHECK\n",
    "    # print(\"llm_data_histogram:\\n\", llm_data_histogram)\n",
    "    # print(\"uniform_histogram:\\n\", uniform_histogram)\n",
    "\n",
    "\n",
    "    # Then, flatten each 3x3x3 matrix into a 1D vector of length 27\n",
    "    llm_vector = llm_data_histogram.flatten()\n",
    "    uniform_vector = uniform_histogram.flatten()\n",
    "\n",
    "    # Then, convert to probability distributions. Since KL Divergence operates on \n",
    "    # probability distributions, normalize each vector so that the sum of its elements is 1\n",
    "    llm_prob = normalize(llm_vector) \n",
    "    uniform_prob = normalize(uniform_vector)\n",
    "\n",
    "    # Next, add smoothing. Since some bins in B_prob are zero, add a small \n",
    "    # smoothing value (1e−9) to avoid division by zero in the KL Divergence calculation\n",
    "    llm_prob_smooth = np.where(llm_prob == 0, 1e-9, llm_prob)\n",
    "    uniform_prob_smooth = np.where(uniform_prob == 0, 1e-9, uniform_prob)  \n",
    "\n",
    "    print(f\"\\n\\n@@@ Jensen-Shannon Distance Betweem LLM-Generated Audio State '{state}' and Uniform Distribution @@@\\n\")\n",
    "\n",
    "    JS_distance = jensen_shannon_distance(llm_prob_smooth, human_prob_smooth)\n",
    "    print(f\">>> Jensen-Shannon Distance for the state {state} is: {JS_distance:.3f}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
