{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for KL Leibler Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/liamroy/Documents/Studies/Monash_31194990/PHD/Studies/Study_03/LLM_motion/llm_audio_testcase/stats'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@ Kullback–Leibler Divergence For State: stuck @@@@@@@@@@@@@@@\n",
      "\n",
      "LLM DATA |3x3x3 Histogram Matrix for stuck:\n",
      "[[[69  0  0]\n",
      "  [ 2  0  0]\n",
      "  [ 9  0  0]]\n",
      "\n",
      " [[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]\n",
      "\n",
      " [[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]]\n",
      "HUMAN DATA | 3x3x3 Histogram Matrix for stuck:\n",
      "[[[9 1 0]\n",
      "  [1 0 0]\n",
      "  [4 0 0]]\n",
      "\n",
      " [[2 0 0]\n",
      "  [0 0 0]\n",
      "  [1 0 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 0 0]\n",
      "  [5 0 0]]]\n",
      "\n",
      " >>> KL Divergence for the state stuck is: 0.661\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@ Kullback–Leibler Divergence For State: accomplished @@@@@@@@@@@@@@@\n",
      "\n",
      "LLM DATA |3x3x3 Histogram Matrix for accomplished:\n",
      "[[[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]\n",
      "\n",
      " [[ 0  0  2]\n",
      "  [ 0  0 24]\n",
      "  [ 0  0 33]]\n",
      "\n",
      " [[ 0  0  0]\n",
      "  [ 0  0 12]\n",
      "  [ 0  0  9]]]\n",
      "HUMAN DATA | 3x3x3 Histogram Matrix for accomplished:\n",
      "[[[0 0 3]\n",
      "  [0 1 2]\n",
      "  [0 1 1]]\n",
      "\n",
      " [[0 0 2]\n",
      "  [0 0 2]\n",
      "  [0 0 1]]\n",
      "\n",
      " [[0 0 2]\n",
      "  [0 0 5]\n",
      "  [1 1 2]]]\n",
      "\n",
      " >>> KL Divergence for the state accomplished is: 1.284\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@ Kullback–Leibler Divergence For State: progressing @@@@@@@@@@@@@@@\n",
      "\n",
      "LLM DATA |3x3x3 Histogram Matrix for progressing:\n",
      "[[[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]\n",
      "\n",
      " [[ 0  0  0]\n",
      "  [ 0  2 78]\n",
      "  [ 0  0  0]]\n",
      "\n",
      " [[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]]\n",
      "HUMAN DATA | 3x3x3 Histogram Matrix for progressing:\n",
      "[[[0 5 1]\n",
      "  [0 2 0]\n",
      "  [0 1 1]]\n",
      "\n",
      " [[0 5 0]\n",
      "  [0 1 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 5 0]\n",
      "  [0 1 0]\n",
      "  [0 2 0]]]\n",
      "\n",
      " >>> KL Divergence for the state progressing is: 20.168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conditions = [\"llm\", \"human\"]\n",
    "states = [\"stuck\", \"accomplished\", \"progressing\"]\n",
    "\n",
    "for state in states:\n",
    "    print(f\"\\n\\n@@@@@@@@@@@@@@@ Kullback–Leibler Divergence For State: {state} @@@@@@@@@@@@@@@\\n\")\n",
    "\n",
    "    # FIRST DO LLM COND:\n",
    "    # Load the data from the Excel file, specifying the sheet name\n",
    "    llm_file_path = './../llm_audio_rawdata.xlsx'  # Replace with your file path\n",
    "    llm_data = pd.read_excel(llm_file_path,sheet_name='llm_' + state + '_00', usecols=\"D:F\", nrows=80)\n",
    "\n",
    "    mapping = {'A': 0, 'B': 1, 'C': 2}\n",
    "    llm_data = llm_data.replace(mapping).infer_objects()\n",
    "\n",
    "    # Convert data to numeric values, coercing errors (e.g., empty cells or non-numeric text will become NaN)\n",
    "    llm_data = llm_data.apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Ensure the data values are between 0 and 2 as required\n",
    "    assert llm_data.values.max() <= 2 and llm_data.values.min() >= 0, \"Values out of range (0, 1, 2)\"\n",
    "\n",
    "    # Initialize a 3x3x3 numpy array to hold the histogram counts\n",
    "    llm_data_histogram = np.zeros((3, 3, 3), dtype=int)\n",
    "\n",
    "    # Iterate through each row in the DataFrame and bin the data\n",
    "    for row in llm_data.itertuples(index=False):\n",
    "        x, y, z = row  # Unpack the three-vector (each value will be 0, 1, or 2)\n",
    "        llm_data_histogram[x, y, z] += 1\n",
    "\n",
    "    print(f\"LLM DATA |3x3x3 Histogram Matrix for {state}:\")\n",
    "    print(llm_data_histogram)\n",
    "\n",
    "\n",
    "    # THEN DO HUMAN COND:\n",
    "    # Load the data from the Excel file, specifying the sheet name\n",
    "    human_file_path = './../llm_audio_rawdata.xlsx'  # Replace with your file path\n",
    "    human_data = pd.read_excel(human_file_path,sheet_name='human_' + state + '_00', usecols=\"D:F\", nrows=24)\n",
    "\n",
    "    mapping = {'A': 0, 'B': 1, 'C': 2}\n",
    "    human_data = human_data.replace(mapping).infer_objects()\n",
    "\n",
    "    # Convert data to numeric values, coercing errors (e.g., empty cells or non-numeric text will become NaN)\n",
    "    human_data = human_data.apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Ensure the data values are between 0 and 2 as required\n",
    "    assert human_data.values.max() <= 2 and human_data.values.min() >= 0, \"Values out of range (0, 1, 2)\"\n",
    "\n",
    "    # Initialize a 3x3x3 numpy array to hold the histogram counts\n",
    "    human_data_histogram = np.zeros((3, 3, 3), dtype=int)\n",
    "\n",
    "    # Iterate through each row in the DataFrame and bin the data\n",
    "    for row in human_data.itertuples(index=False):\n",
    "        x, y, z = row  # Unpack the three-vector (each value will be 0, 1, or 2)\n",
    "        human_data_histogram[x, y, z] += 1\n",
    "\n",
    "    print(f\"HUMAN DATA | 3x3x3 Histogram Matrix for {state}:\")\n",
    "    print(human_data_histogram)\n",
    "\n",
    "\n",
    "    # Then, flatten each 3x3x3 matrix into a 1D vector of length 27\n",
    "    llm_vector = llm_data_histogram.flatten()\n",
    "    human_vector = human_data_histogram.flatten()\n",
    "\n",
    "\n",
    "    # Then, convert to probability distributions. Since KL Divergence operates on \n",
    "    # probability distributions, normalize each vector so that the sum of its elements is 1\n",
    "    llm_prob = llm_vector / llm_vector.sum()\n",
    "    human_prob = human_vector / human_vector.sum()\n",
    "\n",
    "    # Next, add smoothing. Since some bins in B_prob are zero, add a small \n",
    "    # smoothing value (1e−9) to avoid division by zero in the KL Divergence calculation\n",
    "    llm_prob = np.where(llm_prob == 0, 1e-9, llm_prob)\n",
    "    human_prob = np.where(human_prob == 0, 1e-9, human_prob)  \n",
    "\n",
    "    # Finally, compute KL Divergence using the formula:KL_divergence = np.sum(seriesA * np.log(seriesA / seriesB))\n",
    "    # This quantifies how how much Series B diverges from Series A, capturing the \"distance\" between the two distributions. \n",
    "    # Lower values indicate greater similarity, meaning Series A is more contained within Series B.\n",
    "\n",
    "    KL_divergence = np.sum(llm_prob * np.log(llm_prob / human_prob))\n",
    " \n",
    "    print(f\"\\n >>> KL Divergence for the state {state} is: {KL_divergence:.3f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARCHIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the same approach but with weights that reflect the importance of each parameter.\n",
    "\n",
    "In our prior work, we conducted an anlysis on the influence of each parameter with regards to participants perception of a given sound. This analysis revealed a non-uniform parameter effects.\n",
    "\n",
    "Using a regression, we statistically proved that Pitch Bend had a highly significant influence (p-Value=4.71e08), BPL had a significant influence (p-Value=0.0246), and BPM yielded no significance.\n",
    "\n",
    "Therefore, below we counduct the same approach Kullback-Leibler (KL) Divergence calculations but with weights that reflect the importance of each parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[25.   2.5 25. ]\n",
      "  [10.   1.  10. ]\n",
      "  [25.   2.5 25. ]]\n",
      "\n",
      " [[25.   2.5 25. ]\n",
      "  [10.   1.  10. ]\n",
      "  [25.   2.5 25. ]]\n",
      "\n",
      " [[25.   2.5 25. ]\n",
      "  [10.   1.  10. ]\n",
      "  [25.   2.5 25. ]]]\n"
     ]
    }
   ],
   "source": [
    "# WEIGHTS USED\n",
    "\n",
    "bpm_weight = 1\n",
    "bpl_weight = 2.5\n",
    "pitchbend_weight = 10\n",
    "\n",
    "weights = np.ones((3, 3, 3))\n",
    "\n",
    "weights[0, :, :] *= bpm_weight \n",
    "weights[2, :, :] *= bpm_weight \n",
    "\n",
    "weights[:, 0, :] *= bpl_weight  \n",
    "weights[:, 2, :] *= bpl_weight  \n",
    "\n",
    "weights[:, :, 0] *= pitchbend_weight  \n",
    "weights[:, :, 2] *= pitchbend_weight \n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@ Kullback–Leibler Divergence For State: stuck @@@@@@@@@@@@@@@\n",
      "\n",
      "LLM DATA |3x3x3 Histogram Matrix for stuck:\n",
      "[[[69  0  0]\n",
      "  [ 2  0  0]\n",
      "  [ 9  0  0]]\n",
      "\n",
      " [[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]\n",
      "\n",
      " [[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]]\n",
      "HUMAN DATA | 3x3x3 Histogram Matrix for stuck:\n",
      "[[[9 1 0]\n",
      "  [1 0 0]\n",
      "  [4 0 0]]\n",
      "\n",
      " [[2 0 0]\n",
      "  [0 0 0]\n",
      "  [1 0 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 0 0]\n",
      "  [5 0 0]]]\n",
      "\n",
      " >>> Weighted KL Divergence for the state stuck is: 0.630\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@ Kullback–Leibler Divergence For State: accomplished @@@@@@@@@@@@@@@\n",
      "\n",
      "LLM DATA |3x3x3 Histogram Matrix for accomplished:\n",
      "[[[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]\n",
      "\n",
      " [[ 0  0  2]\n",
      "  [ 0  0 24]\n",
      "  [ 0  0 33]]\n",
      "\n",
      " [[ 0  0  0]\n",
      "  [ 0  0 12]\n",
      "  [ 0  0  9]]]\n",
      "HUMAN DATA | 3x3x3 Histogram Matrix for accomplished:\n",
      "[[[0 0 3]\n",
      "  [0 1 2]\n",
      "  [0 1 1]]\n",
      "\n",
      " [[0 0 2]\n",
      "  [0 0 2]\n",
      "  [0 0 1]]\n",
      "\n",
      " [[0 0 2]\n",
      "  [0 0 5]\n",
      "  [1 1 2]]]\n",
      "\n",
      " >>> Weighted KL Divergence for the state accomplished is: 1.383\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@ Kullback–Leibler Divergence For State: progressing @@@@@@@@@@@@@@@\n",
      "\n",
      "LLM DATA |3x3x3 Histogram Matrix for progressing:\n",
      "[[[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]\n",
      "\n",
      " [[ 0  0  0]\n",
      "  [ 0  2 78]\n",
      "  [ 0  0  0]]\n",
      "\n",
      " [[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]]\n",
      "HUMAN DATA | 3x3x3 Histogram Matrix for progressing:\n",
      "[[[0 5 1]\n",
      "  [0 2 0]\n",
      "  [0 1 1]]\n",
      "\n",
      " [[0 5 0]\n",
      "  [0 1 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 5 0]\n",
      "  [0 1 0]\n",
      "  [0 2 0]]]\n",
      "\n",
      " >>> Weighted KL Divergence for the state progressing is: 20.664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    print(f\"\\n\\n@@@@@@@@@@@@@@@ Kullback–Leibler Divergence For State: {state} @@@@@@@@@@@@@@@\\n\")\n",
    "\n",
    "    # FIRST DO LLM COND:\n",
    "    # Load the data from the Excel file, specifying the sheet name\n",
    "    llm_file_path = './../llm_audio_rawdata.xlsx'  # Replace with your file path\n",
    "    llm_data = pd.read_excel(llm_file_path, sheet_name='llm_' + state + '_00', usecols=\"D:F\", nrows=80)\n",
    "\n",
    "    mapping = {'A': 0, 'B': 1, 'C': 2}\n",
    "    llm_data = llm_data.replace(mapping).infer_objects()\n",
    "\n",
    "    # Convert data to numeric values, coercing errors\n",
    "    llm_data = llm_data.apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Ensure the data values are between 0 and 2 as required\n",
    "    assert llm_data.values.max() <= 2 and llm_data.values.min() >= 0, \"Values out of range (0, 1, 2)\"\n",
    "\n",
    "    # Initialize a 3x3x3 numpy array to hold the histogram counts\n",
    "    llm_data_histogram = np.zeros((3, 3, 3), dtype=int)\n",
    "\n",
    "    # Iterate through each row in the DataFrame and bin the data\n",
    "    for row in llm_data.itertuples(index=False):\n",
    "        x, y, z = row  # Unpack the three-vector (each value will be 0, 1, or 2)\n",
    "        llm_data_histogram[x, y, z] += 1\n",
    "\n",
    "    print(f\"LLM DATA |3x3x3 Histogram Matrix for {state}:\")\n",
    "    print(llm_data_histogram)\n",
    "\n",
    "    # THEN DO HUMAN COND:\n",
    "    # Load the data from the Excel file, specifying the sheet name\n",
    "    human_file_path = './../llm_audio_rawdata.xlsx'  # Replace with your file path\n",
    "    human_data = pd.read_excel(human_file_path, sheet_name='human_' + state + '_00', usecols=\"D:F\", nrows=24)\n",
    "\n",
    "    mapping = {'A': 0, 'B': 1, 'C': 2}\n",
    "    human_data = human_data.replace(mapping).infer_objects()\n",
    "\n",
    "    # Convert data to numeric values, coercing errors\n",
    "    human_data = human_data.apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Ensure the data values are between 0 and 2 as required\n",
    "    assert human_data.values.max() <= 2 and human_data.values.min() >= 0, \"Values out of range (0, 1, 2)\"\n",
    "\n",
    "    # Initialize a 3x3x3 numpy array to hold the histogram counts\n",
    "    human_data_histogram = np.zeros((3, 3, 3), dtype=int)\n",
    "\n",
    "    # Iterate through each row in the DataFrame and bin the data\n",
    "    for row in human_data.itertuples(index=False):\n",
    "        x, y, z = row  # Unpack the three-vector (each value will be 0, 1, or 2)\n",
    "        human_data_histogram[x, y, z] += 1\n",
    "\n",
    "    print(f\"HUMAN DATA | 3x3x3 Histogram Matrix for {state}:\")\n",
    "    print(human_data_histogram)\n",
    "\n",
    "    # Apply weights\n",
    "    weighted_llm_data_histogram = llm_data_histogram * weights\n",
    "    weighted_human_data_histogram = human_data_histogram * weights\n",
    "\n",
    "    # Flatten each 3x3x3 matrix into a 1D vector of length 27\n",
    "    llm_vector = weighted_llm_data_histogram.flatten()\n",
    "    human_vector = weighted_human_data_histogram.flatten()\n",
    "\n",
    "    # Convert to probability distributions, normalize each vector so that the sum of its elements is 1\n",
    "    llm_prob = llm_vector / llm_vector.sum()\n",
    "    human_prob = human_vector / human_vector.sum()\n",
    "\n",
    "    # Add smoothing\n",
    "    llm_prob = np.where(llm_prob == 0, 1e-9, llm_prob)\n",
    "    human_prob = np.where(human_prob == 0, 1e-9, human_prob)\n",
    "\n",
    "    # Finally, compute the weighted KL Divergence\n",
    "    weighted_KL_divergence = np.sum(llm_prob * np.log(llm_prob / human_prob))\n",
    "\n",
    "    print(f\"\\n >>> Weighted KL Divergence for the state {state} is: {weighted_KL_divergence:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
