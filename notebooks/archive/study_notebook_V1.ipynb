{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "874baada-b757-4a4b-b973-1672b287326f",
   "metadata": {},
   "source": [
    "# User Study 02 - RL Audio Notebook\n",
    "\n",
    "Before starting this survey, please click the folliwng two links to read the explanatory statrement and answer the pre-study questionnaire.\n",
    "\n",
    "<span style=\"color:yellow\">**Explanatory Statement:**</span> https://drive.google.com/file/d/1-8npbW1wg_ABzBnnGa1dgEgCaYjDED8o/view?usp=sharing\n",
    "\n",
    "<span style=\"color:yellow\">**Pre-study Questionnaire:**</span> https://forms.gle/GAU8xzekWKkTMDLVA   (Participant ID Required)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2cc91e-71da-4d55-81ed-a10848f4e6a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23022b2d-e155-48ac-b0fd-8a9aa00619a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports & Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00ed503-2ddc-4628-9953-8bb78dfc39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/Documents/PHD/repos/RL_audio/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810beac1-8c6f-422e-92c1-2bbe9e8f6fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PWD = %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1d014-71ea-4649-a013-347682ce55dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import linecache\n",
    "\n",
    "from scripts import audio_control\n",
    "from scripts import ucb1_algorithm as ucb1\n",
    "from scripts import misc_helpers as mischelp\n",
    "\n",
    "import sys\n",
    "from termcolor import colored, cprint\n",
    "# Termcolor guide: https://pypi.org/project/termcolor/\n",
    "\n",
    "#  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#  ARGUMENTS & PARSER (Save this code for scripts working with CLI)\n",
    "\n",
    "# argParser = argparse.ArgumentParser()\n",
    "\n",
    "# # Enter any valid integer value\n",
    "# argParser.add_argument(\"-b\", \"--budg\", required=False, help=\"select the budget value (dtype=int)\")\n",
    "\n",
    "# # Enter a valid parameter discritization integer (must match sound library size)\n",
    "# argParser.add_argument(\"-d\", \"--disc\", required=False, help=\"select discritization size (dtype=int)\")\n",
    "\n",
    "# # Enter true if you would like to see hidden print log, including Q-tables\n",
    "# argParser.add_argument(\"-p\", \"--prnt\", required=False, help=\"show hidden print log (dtype=bool)\")\n",
    "\n",
    "# # To load and save, simply enter in the base filename such as \"lastsave\" or \"set_A\", system takes care of rest\n",
    "# argParser.add_argument(\"-s\", \"--save\", required=False, help=\"filename to save Q-table on exit (dtype=str)\") \n",
    "# argParser.add_argument(\"-l\", \"--load\", required=False, help=\"load Q-table from filename (dtype=str)\") \t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a1705-a32d-4cf4-88f7-9cf7a14a45bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c6de3-9aef-42ae-bb33-8a48c08c79f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter discritization\n",
    "param_disc = 3 \n",
    "\n",
    "state_descriptions = [\"Stuck\t  \\t- robot needs your help\", \"Successful \\t- robot has completed it's task\", \"Progressing \\t- robot is working and doesn't need help\", \"None of the above\"]\n",
    "num_of_states = len(state_descriptions) - 1 # Adding a minus 1 since the last state in \"state_descriptions\" is \"none of the above\"\n",
    "state_range = np.arange(num_of_states)\n",
    "\n",
    "\n",
    "# CREATE SOUND LIBRARY A\n",
    "# For library A, setup the array using libA\n",
    "library_A = \"libA\"\n",
    "\n",
    "# Create an array of size (N x N x N) where N = number of discretized regions\n",
    "# number of discretized regions for each param --> i.e. if equals 3 then (0, 1, 2)\n",
    "# ** must align with the discretization for selected sound library\n",
    "sound_obj_array_A = np.ndarray((param_disc, param_disc, param_disc),dtype=object)\n",
    "\n",
    "for param_1_range in range(param_disc):\n",
    "\tfor param_2_range in range(param_disc):\n",
    "\t\tfor param_3_range in range(param_disc):\n",
    "\t\t\tsound_obj_array_A[param_1_range, param_2_range, param_3_range] = audio_control.audio_object(param_1=param_1_range, param_2=param_2_range, param_3=param_3_range, sound_library=library_A)\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "# CREATE SOUND LIBRARY B\n",
    "# For library B, setup the array using libB\n",
    "library_B = \"libB\"\n",
    "\n",
    "# Create an array of size (N x N x N) where N = number of discretized regions\n",
    "# number of discretized regions for each param --> i.e. if equals 3 then (0, 1, 2)\n",
    "# ** must align with the discretization for selected sound library\n",
    "sound_obj_array_B = np.ndarray((param_disc, param_disc, param_disc),dtype=object)\n",
    "\n",
    "for param_1_range in range(param_disc):\n",
    "\tfor param_2_range in range(param_disc):\n",
    "\t\tfor param_3_range in range(param_disc):\n",
    "\t\t\tsound_obj_array_B[param_1_range, param_2_range, param_3_range] = audio_control.audio_object(param_1=param_1_range, param_2=param_2_range, param_3=param_3_range, sound_library=library_B)\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0567c300-989f-40c8-b1be-69510f22ccab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MAIN STUDY\n",
    "\n",
    "Welcome to this study's <span style=\"color:yellow\">**Jupyter notebook**</span>. In this work, we are developing strategies for improving human-robot interaction with nonverbal sounds (<span style=\"color:yellow\">**_beeps & boops_**</span>).\n",
    "\n",
    "While a robot is working on a task, it can have many different internal states... \n",
    "\n",
    "If the robot gets stuck behind an obstacle, the robot's internal state is: <span style=\"color:Red\">**Stuck**</span>\n",
    "\n",
    "Similarly, if the robot was able to reach it's goal, the robot's internal state is: <span style=\"color:green\">**Successful**</span>\n",
    "\n",
    "If the robot is actively working on the task but has neither gotten stuck nor completed the task, the robot's internal state is: <span style=\"color:blue\">**Progressing**</span>\n",
    "\n",
    "In this notebook, you will be asked to run through <span style=\"color:yellow\">**3 sections**</span>. In each of these sections, a virtual robot will play a sound. Once you listen to the sound, you will be asked to select which robot state you think the virtual robot is in. You will have the options: <span style=\"color:Red\">**Stuck**</span>, <span style=\"color:green\">**Successful**</span>, <span style=\"color:blue\">**Progressing**</span> and <span style=\"color:orange\">**Not Sure**</span>\n",
    "\n",
    "In addition to each answer, you will also self-score how confident you are in your response, on a scale from 1 to 10. \n",
    "\n",
    "This process will repeat several times as a learning algorithm is processing in the background. <span style=\"color:yellow\">**If you have any questions, ask your study moderator**</span>. Have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa9c7e5-1539-481d-817a-a4289ec499c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SECTION 1\n",
    "\n",
    "Start by entering your user ID. \n",
    "\t\n",
    "<span style=\"color:yellow\">**Click on the first cell below & hit 'shift + enter'...**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f50b0a-b88d-4d55-a9e8-dfd8e7bd1ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "current_user_ID_str = mischelp.get_user_ID(parent_dir=PWD, num_of_states=num_of_states)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281452a7-d84d-4b23-88c6-c8c758cede9e",
   "metadata": {},
   "source": [
    "<span style=\"color:yellow\">**Our first robot is named Jackal.**</span>\n",
    "\n",
    "<img src=\"images/jackal.png\" alt=\"Jackal Robot\" style=\"height: 334px; width:600px;\"/>\n",
    "\n",
    "Let's listen to <span style=\"color:yellow\">**Jackal**</span> make a few sounds to express itself. \n",
    "\n",
    "For each sound, you will asked to select which robot state you think the robot is in.\n",
    "\n",
    "<span style=\"color:yellow\">**Click on the cell below & hit 'shift + enter'...**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b7585-4d7b-4110-bf9e-a9a98157462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "mischelp.get_user_accuracy(sound_obj_array=sound_obj_array_A, lib_str=library_A, sect_str=\"sect1\", user_ID_str=current_user_ID_str, num_of_states=num_of_states, \n",
    "                           states_array=np.ndarray(num_of_states, dtype=object), state_descriptions=state_descriptions, param_disc=param_disc, load_file=\"pilotset\", seed=70)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57c4fd1-8c94-47e1-a158-bf2c574c0421",
   "metadata": {},
   "source": [
    "<span style=\"color:yellow\">**Our next robot is named the Spot.**</span>\n",
    "\n",
    "<img src=\"images/spot.png\" alt=\"Jackal Robot\" style=\"height: 334px; width:600px;\"/>\n",
    "\n",
    "Let's listen to <span style=\"color:yellow\">**Spot**</span> make a few sounds to express itself. \n",
    "\n",
    "You will notice <span style=\"color:yellow\">**Spot**</span> sounds slightly different to <span style=\"color:yellow\">**Jackal**</span>. For each sound, you will asked to select which robot state you think the robot is in.\n",
    "\n",
    "<span style=\"color:yellow\">**Click on the cell below & hit 'shift + enter'...**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d522dad9-f3fc-45c4-871c-39035dd2234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "mischelp.get_user_accuracy(sound_obj_array=sound_obj_array_B, lib_str=library_B, sect_str=\"sect1\", user_ID_str=current_user_ID_str, num_of_states=num_of_states, \n",
    "                           states_array=np.ndarray(num_of_states, dtype=object), state_descriptions=state_descriptions, param_disc=param_disc, load_file=\"pilotset\", seed=51)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05ca2de-78ed-4687-80e7-3b81400b4072",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Section 2\n",
    "\n",
    "In section 2, we'll be listening to <span style=\"color:yellow\">**Jackal**</span> again.\n",
    "\n",
    "<img src=\"images/jackal.png\" alt=\"Jackal Robot\" style=\"height: 334px; width:600px;\"/>\n",
    "\n",
    "Similar to before, <span style=\"color:yellow\">**Jackal**</span> make a few sounds to express itself, and you will asked to select which robot state you think the robot is in.\n",
    "\n",
    "This process will repeat several times as a learning algorithm is processing in the background."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50631102-91eb-45e8-b7e9-f58f59cc15c1",
   "metadata": {},
   "source": [
    "### Section 2X\n",
    "\n",
    "<span style=\"color:yellow\">**Click on the cell below & hit 'shift + enter'...**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98abe79-eb5b-4f08-a2af-081dcd15d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "time_step_2X_str = ucb1.ucb1_algor(num_of_states=num_of_states, state_descriptions=state_descriptions, param_disc=param_disc, sound_obj_array=sound_obj_array_A, \n",
    "                               current_user_ID_str=current_user_ID_str, sect_str=\"_sect2X\", load_file=None, budget=50, delta_Q_thresh=2.0, conv_thresh=3, printer=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e765ff7-c847-4eac-8890-4db2a261dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "time_step_2X_str = ucb1.ucb1_algor(num_of_states=num_of_states, state_descriptions=state_descriptions, param_disc=param_disc, sound_obj_array=sound_obj_array_A, \n",
    "                               current_user_ID_str=current_user_ID_str, sect_str=\"_sect2O\", load_file=\"pilotset\", budget=50, delta_Q_thresh=2.0, conv_thresh=3, printer=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ef0ee7-fc18-4116-a330-d0769cfe1905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializations:\n",
    "time_step_2X = 0\t \t\t# Initialize time_step_2X to zero\n",
    "budget = 50\t   \t\t\t# Max number of total iterations \n",
    "\n",
    "# Convergence markers\n",
    "delta_Q_thresh = 2.0\t# Change in Q value of a given state action-value \n",
    "conv_thresh = 3\t\t\t# How many times a state is guessed correctly in a row before that state converges\n",
    "\n",
    "save_file = current_user_ID_str + \"_sect2X\"\t# Filename to save Q-table on exit\n",
    "load_file = None\t\t\t\t\t\t\t# No loadfile sets matrix to flat (set to either None, \"pilotset\" or other)\n",
    "\n",
    "printer = True\t\t\t# Either set to True or None (prints hidden statements for debug)\n",
    "\n",
    "\n",
    "# Initialize convergece param markers to None\n",
    "prev_st0_param_1_idx, prev_st0_param_2_idx, prev_st0_param_3_idx = None, None, None\n",
    "prev_st1_param_1_idx, prev_st1_param_2_idx, prev_st1_param_3_idx = None, None, None\n",
    "prev_st2_param_1_idx, prev_st2_param_2_idx, prev_st2_param_3_idx = None, None, None\n",
    "\n",
    "\n",
    "# Set initial convergence markers to zero\n",
    "in_a_row_st0 = 0\n",
    "in_a_row_st1 = 0\n",
    "in_a_row_st2 = 0\n",
    "\n",
    "\n",
    "# Re-Initialize states array. Each state is initialized with a Q-table based on load_file\n",
    "states_array = np.ndarray(num_of_states, dtype=object)\n",
    "for state_idx in range(num_of_states):\n",
    "\tstates_array[state_idx] = ucb1.robot_state(state_idx=state_idx, description=state_descriptions[state_idx], param_disc=param_disc, \n",
    "\t\t\t\t\t\t\t\t\t\t\t   load_file=load_file, user_ID_str=current_user_ID_str)\n",
    "\n",
    "\t\n",
    "# Creates the initial set of {0, 1, 2) which the for loop will sample from to choose a state index\n",
    "state_idx_set = set()\n",
    "for state_idx in range(num_of_states):\n",
    "\tstate_idx_set.add(state_idx)\n",
    "\t\n",
    "\n",
    "for param_1_range in range(param_disc):\n",
    "\tfor param_2_range in range(param_disc):\n",
    "\t\tfor param_3_range in range(param_disc):\n",
    "\t\t\tsound_obj_array_A[param_1_range, param_2_range, param_3_range].initialize()\n",
    "    \n",
    "\n",
    "# Run a for loop which plays a sound, gets a response, then updates. Itterations is the budget\n",
    "for i in range(0, budget):\n",
    "\t\n",
    "\tcurrent_state_index = random.choice(tuple(state_idx_set)) \t\t# Current actual state of the robot - change this to fluctuate during study\n",
    "\t\n",
    "\tif printer:\n",
    "\t\tprint(\"state_idx_set:\", state_idx_set)\n",
    "\t\tprint(\"current_state_index:\", current_state_index)\n",
    "\t\n",
    "\tif time_step_2X == 0 and load_file == None:\n",
    "\t\tparam_1_idx = 1 \n",
    "\t\tparam_2_idx = 1\n",
    "\t\tparam_3_idx = 1\n",
    "\telse:\n",
    "\t# Select new params\n",
    "\t\tparam_1_idx, param_2_idx, param_3_idx = states_array[current_state_index].action_selection()\n",
    "\n",
    "\ttime_step_2X_str = f\"{time_step_2X:02}\"\n",
    "\n",
    "\tif printer:\n",
    "\t\tprint(\"\\n----------------------------------------------------------------\")\n",
    "\t\tprint(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "\t\tprint(\"----------------------------------------------------------------\\n\")\n",
    "\t\tprint(f\"Time Step: {time_step_2X_str}\")\n",
    "\n",
    "\ttime_step_2X += 1\n",
    "\t\n",
    "\tif printer:\n",
    "\t\tprint(\"(Hidden):\")\n",
    "\t\tprint(f\"New Param INDICES (not direct values): \\nP1: {param_1_idx} (Beats per Minute - BPM) \\nP2: {param_2_idx} (Beeps per Loop - BPL) \\nP3: {param_3_idx} (Amplitude of Pitch Change)\\n\")\n",
    "\n",
    "\n",
    "\t# Play the desired mp3 file & probe user for perceived state & confidence in their response\n",
    "\tprobed_state_index, probed_confidence = sound_obj_array_A[param_1_idx, param_2_idx, param_3_idx].probe(state_descriptions)\n",
    "\n",
    "\t# Update N for audio obj\n",
    "\tsound_obj_array_A[param_1_idx, param_2_idx, param_3_idx].update()\n",
    "\n",
    "\t# Calculate uncertainty signal (U_t) based on N and time_step_2X\n",
    "\tuncertainty_signal = sound_obj_array_A[param_1_idx, param_2_idx, param_3_idx].uncertainty(time_step_2X)\n",
    "\n",
    "\t# For each state, calculate the respective reward signal (R)\n",
    "\tfor state_idx in range(num_of_states):\n",
    "\n",
    "\t\t# If the user enters [3] \"Unsure\", reward signal is zero\n",
    "\t\tif probed_state_index == len(state_descriptions) - 1:\n",
    "\t\t\treward_signal = 0.0\n",
    "\n",
    "\t\t# Otherwise we calculate reward based on: correct * confidence\n",
    "\t\telse:\n",
    "\t\t\tif probed_state_index == state_idx:\n",
    "\t\t\t\tcorrect_multiplier = 1.0\n",
    "\t\t\telif probed_state_index != state_idx:\n",
    "\t\t\t\tcorrect_multiplier = -1.0\n",
    "\n",
    "\t\t\t# This is the reward signal R\n",
    "\t\t\treward_signal = correct_multiplier * probed_confidence\n",
    "\n",
    "\t\t# Calculate new Q_t = {[(1 - 1/n) * Q_t-1] + [(1/n) * R]} + U_t   ~  UCB1 algorithm update equation\n",
    "\t\t# Takes the mean of previously observed reward and new reward, adding on an uncertainty term\n",
    "\t\tprint(f\"state {state_idx} n.val is {sound_obj_array_A[param_1_idx, param_2_idx, param_3_idx].n}\")\n",
    "\t\tQ_value = ((1 - 1.0/sound_obj_array_A[param_1_idx, param_2_idx, param_3_idx].n) * states_array[state_idx].action_value_lookup[param_1_idx, param_2_idx, param_3_idx] + (1.0/sound_obj_array_A[param_1_idx, param_2_idx, param_3_idx].n) * reward_signal) + uncertainty_signal\n",
    "\n",
    "\t\t\n",
    "\t\tdelta_Q = abs(Q_value - states_array[state_idx].action_value_lookup[param_1_idx, param_2_idx, param_3_idx])\n",
    "\t\t\t\t\n",
    "\t\t# def converg here .. \n",
    "\t\t\n",
    "\t\t# Update value in lookup table for state S with new Q_t \n",
    "\t\t# Added an np.clip so that the mix/max Q-Value in the table cant exceed -10 to +10\n",
    "\t\tstates_array[state_idx].action_value_lookup[param_1_idx, param_2_idx, param_3_idx] = np.clip(Q_value, -10, 10)\n",
    "\n",
    "\t\t\n",
    "\t\t# A few print statements for terminal\n",
    "\t\tif printer:\n",
    "\t\t\tprint(\"\\n\\n----------------------------------------------------------------\\n\")\n",
    "\t\t\tprint(\"(Hidden):\")\n",
    "\t\t\tprint(f\"Uncertainty_signal (U):\\t {uncertainty_signal}\")\n",
    "\t\t\tprint(f\"Reward_signal (R):\\t {reward_signal}\")\n",
    "\t\t\tprint(f\"Delta_Q for state {state_idx} is: {delta_Q}\")\n",
    "\t\t\tprint(f\"New action value (Q):\\t {Q_value}\")\n",
    "\t\t\tprint(f\"Q-table after update for state {state_idx}:\\n\")\n",
    "\t\t\tprint(states_array[state_idx].action_value_lookup)\n",
    "\n",
    "\t\t\n",
    "\t\tnp.save(\"user_data/user_\" + current_user_ID_str + \"/arrays/\" + save_file + \"_step\" + time_step_2X_str + \"_st\" + str(state_idx) + \".npy\", states_array[state_idx].action_value_lookup)\n",
    "\n",
    "\t\ttime.sleep(0.5) # Put here to make UI a bit nicer \n",
    "\t\t\n",
    "\t\t\n",
    "\t# Now check to see if there is convergence for each state..\n",
    "\t\n",
    "\t#If probing state 0, did they get it correct?\n",
    "\tif current_state_index == 0:\n",
    "\t\tif probed_state_index == current_state_index and prev_st0_param_1_idx == param_1_idx and prev_st0_param_2_idx == param_2_idx and prev_st0_param_3_idx == param_3_idx:\n",
    "\t\t\tin_a_row_st0 += 1\n",
    "\t\t\tif printer:\n",
    "\t\t\t\tprint(f\"in_a_row_st0 +1, total {in_a_row_st0} becase correct and same\")\n",
    "\t\telif probed_state_index == current_state_index and delta_Q <= delta_Q_thresh: \n",
    "\t\t\tin_a_row_st1 += 1\n",
    "\t\t\tif printer:\n",
    "\t\t\t\tprint(f\"in_a_row_st0 +1, total {in_a_row_st0} becase correct and under delta Q thresh\")\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tin_a_row_st0 = 0\n",
    "\t\t\tif printer:\n",
    "\t\t\t\tprint(f\"in_a_row_st0 back to zero\")\n",
    "\n",
    "\t\tprev_st0_param_1_idx, prev_st0_param_2_idx, prev_st0_param_3_idx = param_1_idx, param_2_idx, param_3_idx\n",
    "\n",
    "\t\t\n",
    "\t#If probing state 1, did they get it correct?\n",
    "\tif current_state_index == 1:\n",
    "\t\tif probed_state_index == current_state_index and prev_st1_param_1_idx == param_1_idx and prev_st1_param_2_idx == param_2_idx and prev_st1_param_3_idx == param_3_idx:\n",
    "\t\t\tin_a_row_st1 += 1\n",
    "\t\t\tif printer:\n",
    "\t\t\t\tprint(f\"in_a_row_st1 +1, total {in_a_row_st1} becase correct and same\")\n",
    "\t\telif probed_state_index == current_state_index and delta_Q <= delta_Q_thresh: \n",
    "\t\t\tin_a_row_st1 += 1\n",
    "\t\t\tif printer:\n",
    "\t\t\t\tprint(f\"in_a_row_st1 +1, total {in_a_row_st1} becase correct and under delta Q thresh\")\n",
    "\t\telse:\n",
    "\t\t\tin_a_row_st1 = 0\n",
    "\t\t\tif printer:\n",
    "\t\t\t\tprint(f\"in_a_row_st1 back to zero\")\n",
    "\t\t\n",
    "\t\tprev_st1_param_1_idx, prev_st1_param_2_idx, prev_st1_param_3_idx = param_1_idx, param_2_idx, param_3_idx\n",
    "\n",
    "\t\t\n",
    "\t#If probing state 2, did they get it correct?\n",
    "\tif current_state_index == 2:\n",
    "\t\tif probed_state_index == current_state_index and prev_st2_param_1_idx == param_1_idx and prev_st2_param_2_idx == param_2_idx and prev_st2_param_3_idx == param_3_idx:\n",
    "\t\t\tin_a_row_st2 += 1\n",
    "\t\t\tif printer:\n",
    "\t\t\t\tprint(f\"in_a_row_st2 +1, total {in_a_row_st2} becase correct and same\")\n",
    "\t\telif probed_state_index == current_state_index and delta_Q <= delta_Q_thresh: \n",
    "\t\t\tin_a_row_st1 += 1\n",
    "\t\t\tif printer:\n",
    "\t\t\t\tprint(f\"in_a_row_st2 +1, total {in_a_row_st2} becase correct and under delta Q thresh\")\t\t\t\n",
    "\t\telse:\n",
    "\t\t\tin_a_row_st2 = 0\n",
    "\t\t\tif printer:\n",
    "\t\t\t\tprint(f\"in_a_row_st1 back to zero\")\n",
    "\t\t\t\t\n",
    "\t\tprev_st2_param_1_idx, prev_st2_param_2_idx, prev_st2_param_3_idx = param_1_idx, param_2_idx, param_3_idx\n",
    "\t\t\n",
    "\tif in_a_row_st0 >= conv_thresh:\n",
    "\t\tstate_idx_set.discard(0)\n",
    "\t\tif printer:\n",
    "\t\t\tcprint(f\"State 0 Converged\", \"black\", \"on_yellow\", attrs=[\"bold\"])\n",
    "\t\t\n",
    "\tif in_a_row_st1 >= conv_thresh:\n",
    "\t\tstate_idx_set.discard(1)\n",
    "\t\tif printer:\n",
    "\t\t\tcprint(f\"State 1 Converged\", \"black\", \"on_yellow\", attrs=[\"bold\"])\n",
    "\t\n",
    "\tif in_a_row_st2 >= conv_thresh:\n",
    "\t\tstate_idx_set.discard(2)\n",
    "\t\tif printer:\n",
    "\t\t\tcprint(f\"State 2 Converged\", \"black\", \"on_yellow\", attrs=[\"bold\"])\n",
    "\t\t\n",
    "\tif in_a_row_st0 >= conv_thresh and in_a_row_st1 >= conv_thresh and in_a_row_st2 >= conv_thresh:\n",
    "\t\tif printer:\n",
    "\t\t\tprint(\"running 'break' on converge\\n\")\n",
    "\t\tbreak\n",
    "\n",
    "if printer:\n",
    "\tprint(\"in_a_row_st0\", in_a_row_st0)\n",
    "\tprint(\"in_a_row_st1\", in_a_row_st1)\n",
    "\tprint(\"in_a_row_st2\", in_a_row_st2)\n",
    "\tprint(\"final time_step_2X:\", time_step_2X)\n",
    "\n",
    "# Coloured print statement to direct user to next cell\n",
    "cprint(\"\\n\\n\\n------------------------------------------------------------------------\", \"light_yellow\", attrs=[\"bold\"])\n",
    "cprint(\"------------------------------------------------------------------------\\n\", \"light_yellow\", attrs=[\"bold\"])\n",
    "cprint(f\"Great job! The system terminated successfully at itter: {time_step_2X}.\", \"black\", \"on_yellow\", attrs=[\"bold\"])\n",
    "cprint(f\"Click on the next cell below and hit 'shift + enter' to continue\\n\", \"black\", \"on_yellow\", attrs=[\"bold\"])\n",
    "cprint(\"------------------------------------------------------------------------\", \"light_yellow\", attrs=[\"bold\"])\n",
    "cprint(\"------------------------------------------------------------------------\\n\\n\\n\", \"light_yellow\", attrs=[\"bold\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f87f4c-e025-4172-ae7d-16394478c344",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Section 2O\n",
    "\n",
    "<span style=\"color:yellow\">**Click on the cell below & hit 'shift + enter'...**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb07ac2-2581-42ce-b408-8343ba118574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializations:\n",
    "time_step_2O = 0\t \t\t# Initialize time_step_2O to zero\n",
    "budget = 50\t   \t\t\t# Max number of total iterations \n",
    "conv_thresh = 3\t\t\t# How many times a state is guessed correctly in a row before that state converges\n",
    "\n",
    "save_file = current_user_ID_str + \"_sect2O\"\t# Filename to save Q-table on exit\n",
    "load_file = \"pilotset\"  \t\t\t\t\t# No loadfile sets matrix to flat (set to either None, \"pilotset\" or other)\n",
    "\n",
    "printer = None\t\t\t# Either set to True or None (prints hidden statements for debug)\n",
    "\n",
    "\n",
    "# Initialize convergece param markers to None\n",
    "prev_st0_param_1_idx, prev_st0_param_2_idx, prev_st0_param_3_idx = None, None, None\n",
    "prev_st1_param_1_idx, prev_st1_param_2_idx, prev_st1_param_3_idx = None, None, None\n",
    "prev_st2_param_1_idx, prev_st2_param_2_idx, prev_st2_param_3_idx = None, None, None\n",
    "\n",
    "\n",
    "# Set initial convergence markers to zero\n",
    "in_a_row_st0 = 0\n",
    "in_a_row_st1 = 0\n",
    "in_a_row_st2 = 0\n",
    "\n",
    "\n",
    "# Re-Initialize states array. Each state is initialized with a Q-table based on load_file\n",
    "states_array = np.ndarray(num_of_states, dtype=object)\n",
    "for state_idx in range(num_of_states):\n",
    "\tstates_array[state_idx] = ucb1.robot_state(state_idx=state_idx, description=state_descriptions[state_idx], param_disc=param_disc, \n",
    "\t\t\t\t\t\t\t\t\t\t\t   load_file=load_file, user_ID_str=current_user_ID_str)\n",
    "\n",
    "\t\n",
    "# Creates the initial set of {0, 1, 2) which the for loop will sample from to choose a state index\n",
    "state_idx_set = set()\n",
    "for state_idx in range(num_of_states):\n",
    "\tstate_idx_set.add(state_idx)\n",
    "\t\n",
    "\t\n",
    "\n",
    "# Run a for loop which plays a sound, gets a response, then updates. Itterations is the budget\n",
    "for i in range(0, budget):\n",
    "\t\n",
    "\tcurrent_state_index = random.choice(tuple(state_idx_set)) \t\t# Current actual state of the robot - change this to fluctuate during study\n",
    "\t\n",
    "\tif printer:\n",
    "\t\tprint(\"state_idx_set:\", state_idx_set)\n",
    "\t\tprint(\"current_state_index:\", current_state_index)\n",
    "\t\n",
    "\tif time_step_2O == 0 and load_file == None:\n",
    "\t\tparam_1_idx = 1 \n",
    "\t\tparam_2_idx = 1\n",
    "\t\tparam_3_idx = 1\n",
    "\telse:\n",
    "\t# Select new params\n",
    "\t\tparam_1_idx, param_2_idx, param_3_idx = states_array[current_state_index].action_selection()\n",
    "\n",
    "\ttime_step_2O_str = f\"{time_step_2O:02}\"\n",
    "\n",
    "\tif printer:\n",
    "\t\tprint(\"\\n----------------------------------------------------------------\")\n",
    "\t\tprint(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "\t\tprint(\"----------------------------------------------------------------\\n\")\n",
    "\t\tprint(f\"Time Step: {time_step_2O_str}\")\n",
    "\n",
    "\ttime_step_2O += 1\n",
    "\t\n",
    "\tif printer:\n",
    "\t\tprint(\"(Hidden):\")\n",
    "\t\tprint(f\"New Param INDICES (not direct values): \\nP1: {param_1_idx} (Beats per Minute - BPM) \\nP2: {param_2_idx} (Beeps per Loop - BPL) \\nP3: {param_3_idx} (Amplitude of Pitch Change)\\n\")\n",
    "\n",
    "\n",
    "\t# Play the desired mp3 file & probe user for perceived state & confidence in their response\n",
    "\tprobed_state_index, probed_confidence = sound_obj_array_A[param_1_idx, param_2_idx, param_3_idx].probe(state_descriptions)\n",
    "\n",
    "\t# Update N for audio obj\n",
    "\tsound_obj_array_A[param_1_idx, param_2_idx, param_3_idx].update()\n",
    "\n",
    "\t# Calculate uncertainty signal (U_t) based on N and time_step_2O\n",
    "\tuncertainty_signal = sound_obj_array_A[param_1_idx, param_2_idx, param_3_idx].uncertainty(time_step_2O)\n",
    "\n",
    "\t# For each state, calculate the respective reward signal (R)\n",
    "\tfor state_idx in range(num_of_states):\n",
    "\n",
    "\t\t# If the user enters [3] \"Unsure\", reward signal is zero\n",
    "\t\tif probed_state_index == len(state_descriptions) - 1:\n",
    "\t\t\treward_signal = 0.0\n",
    "\n",
    "\t\t# Otherwise we calculate reward based on: correct * confidence\n",
    "\t\telse:\n",
    "\t\t\tif probed_state_index == state_idx:\n",
    "\t\t\t\tcorrect_multiplier = 1.0\n",
    "\t\t\telif probed_state_index != state_idx:\n",
    "\t\t\t\tcorrect_multiplier = -1.0\n",
    "\n",
    "\t\t\t# This is the reward signal R\n",
    "\t\t\treward_signal = correct_multiplier * probed_confidence\n",
    "\n",
    "\t\t# Calculate new Q_t = {[(1 - 1/n) * Q_t-1] + [(1/n) * R]} + U_t   ~  UCB1 algorithm update equation\n",
    "\t\t# Takes the mean of previously observed reward and new reward, adding on an uncertainty term\n",
    "\t\tQ_value = ((1 - 1.0/sound_obj_array_A[param_1_idx, param_2_idx, param_3_idx].n) * states_array[state_idx].action_value_lookup[param_1_idx, param_2_idx, param_3_idx] + (1.0/sound_obj_array_A[param_1_idx, param_2_idx, param_3_idx].n) * reward_signal) + uncertainty_signal\n",
    "\n",
    "\t\t\n",
    "\t\t# Update value in lookup table for state S with new Q_t \n",
    "\t\t# Added an np.clip so that the mix/max Q-Value in the table cant exceed -10 to +10\n",
    "\t\tstates_array[state_idx].action_value_lookup[param_1_idx, param_2_idx, param_3_idx] = np.clip(Q_value, -10, 10)\n",
    "\n",
    "\t\t\n",
    "\t\t# A few print statements for terminal\n",
    "\t\tif printer:\n",
    "\t\t\tprint(\"\\n\\n----------------------------------------------------------------\\n\")\n",
    "\t\t\tprint(\"(Hidden):\")\n",
    "\t\t\tprint(f\"Uncertainty_signal (U):\\t {uncertainty_signal}\")\n",
    "\t\t\tprint(f\"Reward_signal (R):\\t {reward_signal}\")\n",
    "\t\t\tprint(f\"New action value (Q):\\t {Q_value}\")\n",
    "\t\t\tprint(f\"Q-table after update for state {state_idx}:\\n\")\n",
    "\t\t\tprint(states_array[state_idx].action_value_lookup)\n",
    "\n",
    "\t\t\n",
    "\t\tnp.save(\"user_data/user_\" + current_user_ID_str + \"/arrays/\" + save_file + \"_step\" + time_step_2O_str + \"_st\" + str(state_idx) + \".npy\", states_array[state_idx].action_value_lookup)\n",
    "\n",
    "\t\ttime.sleep(0.5) # Put here to make UI a bit nicer \n",
    "\t\t\n",
    "\t\t\n",
    "\t# Now check to see if there is convergence for each state..\n",
    "\t\n",
    "\t#If probing state 0, did they get it correct?\n",
    "\tif current_state_index == 0:\n",
    "\t\tif probed_state_index == current_state_index and prev_st0_param_1_idx == param_1_idx and prev_st0_param_2_idx == param_2_idx and prev_st0_param_3_idx == param_3_idx:\n",
    "\t\t\tin_a_row_st0 += 1\n",
    "\t\telse:\n",
    "\t\t\tin_a_row_st0 = 0\n",
    "\t\t\n",
    "\t\tprev_st0_param_1_idx, prev_st0_param_2_idx, prev_st0_param_3_idx = param_1_idx, param_2_idx, param_3_idx\n",
    "\n",
    "\t\t\n",
    "\t#If probing state 1, did they get it correct?\n",
    "\tif current_state_index == 1:\n",
    "\t\tif probed_state_index == current_state_index and prev_st1_param_1_idx == param_1_idx and prev_st1_param_2_idx == param_2_idx and prev_st1_param_3_idx == param_3_idx:\n",
    "\t\t\tin_a_row_st1 += 1\n",
    "\t\telse:\n",
    "\t\t\tin_a_row_st1 = 0\n",
    "\t\t\n",
    "\t\tprev_st1_param_1_idx, prev_st1_param_2_idx, prev_st1_param_3_idx = param_1_idx, param_2_idx, param_3_idx\n",
    "\n",
    "\t\t\n",
    "\t#If probing state 2, did they get it correct?\n",
    "\tif current_state_index == 2:\n",
    "\t\tif probed_state_index == current_state_index and prev_st2_param_1_idx == param_1_idx and prev_st2_param_2_idx == param_2_idx and prev_st2_param_3_idx == param_3_idx:\n",
    "\t\t\tin_a_row_st2 += 1\n",
    "\t\telse:\n",
    "\t\t\tin_a_row_st2 = 0\n",
    "\t\t\n",
    "\t\tprev_st2_param_1_idx, prev_st2_param_2_idx, prev_st2_param_3_idx = param_1_idx, param_2_idx, param_3_idx\n",
    "\t\t\n",
    "\tif in_a_row_st0 >= conv_thresh:\n",
    "\t\tstate_idx_set.discard(0)\n",
    "\t\tif printer:\n",
    "\t\t\tcprint(f\"State 0 Converged\", \"black\", \"on_yellow\", attrs=[\"bold\"])\n",
    "\t\t\n",
    "\tif in_a_row_st1 >= conv_thresh:\n",
    "\t\tstate_idx_set.discard(1)\n",
    "\t\tif printer:\n",
    "\t\t\tcprint(f\"State 1 Converged\", \"black\", \"on_yellow\", attrs=[\"bold\"])\n",
    "\t\n",
    "\tif in_a_row_st2 >= conv_thresh:\n",
    "\t\tstate_idx_set.discard(2)\n",
    "\t\tif printer:\n",
    "\t\t\tcprint(f\"State 2 Converged\", \"black\", \"on_yellow\", attrs=[\"bold\"])\n",
    "\t\t\n",
    "\tif in_a_row_st0 >= conv_thresh and in_a_row_st1 >= conv_thresh and in_a_row_st2 >= conv_thresh:\n",
    "\t\tif printer:\n",
    "\t\t\tprint(\"running 'break' on converge\\n\")\n",
    "\t\tbreak\n",
    "\n",
    "if printer:\n",
    "\tprint(\"in_a_row_st0\", in_a_row_st0)\n",
    "\tprint(\"in_a_row_st1\", in_a_row_st1)\n",
    "\tprint(\"in_a_row_st2\", in_a_row_st2)\n",
    "\tprint(\"finaltime_step_2O:\", time_step_2O)\n",
    "\n",
    "# Coloured print statement to direct user to next cell\n",
    "cprint(\"\\n\\n\\n------------------------------------------------------------------------\", \"light_yellow\", attrs=[\"bold\"])\n",
    "cprint(\"------------------------------------------------------------------------\\n\", \"light_yellow\", attrs=[\"bold\"])\n",
    "cprint(f\"Great job! The system terminated successfully at itter: {time_step_2O}.\", \"black\", \"on_yellow\", attrs=[\"bold\"])\n",
    "cprint(f\"Click on the next cell below and hit 'shift + enter' to continue\\n\", \"black\", \"on_yellow\", attrs=[\"bold\"])\n",
    "cprint(\"------------------------------------------------------------------------\", \"light_yellow\", attrs=[\"bold\"])\n",
    "cprint(\"------------------------------------------------------------------------\\n\\n\\n\", \"light_yellow\", attrs=[\"bold\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d56f247-e48e-471c-86d2-262572a6ec44",
   "metadata": {},
   "source": [
    "## Section 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9a616f-dd0e-49e0-a454-c7adb5339402",
   "metadata": {},
   "source": [
    "We're nearly finished ~ <span style=\"color:yellow\">**home stretch!**</span>\n",
    "\n",
    "<img src=\"images/jackal.png\" alt=\"Jackal Robot\" style=\"height: 334px; width:600px;\"/>\n",
    "\n",
    "Let's listen to <span style=\"color:yellow\">**Jackal**</span> express itself one last time. \n",
    "\n",
    "For each sound, you will asked to select which robot state you think the robot is in.\n",
    "\n",
    "<span style=\"color:yellow\">**Click on the cell below & hit 'shift + enter'...**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77236d11-3ada-45e1-8dcb-38c8c28f7e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sect3_load_str = current_user_ID_str + \"_sect2O_step\" + time_step_2O_str\n",
    "\n",
    "\n",
    "mischelp.get_user_accuracy(sound_obj_array=sound_obj_array_A, lib_str=library_A, sect_str=\"sect3\", user_ID_str=current_user_ID_str, num_of_states=num_of_states, \n",
    "                           states_array=np.ndarray(num_of_states, dtype=object), state_descriptions=state_descriptions, param_disc=param_disc, load_file=sect3_load_str, seed=51)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611f8cd2-0fc0-4104-9b35-80235e297ec0",
   "metadata": {},
   "source": [
    "<img src=\"images/spot.png\" alt=\"Jackal Robot\" style=\"height: 334px; width:600px;\"/>\n",
    "\n",
    "Lastly, let's listen to <span style=\"color:yellow\">**Spot**</span> express itself one last time.  \n",
    "\n",
    "You will notice <span style=\"color:yellow\">**Spot**</span> sounds slightly different to <span style=\"color:yellow\">**Jackal**</span>. For each sound, you will asked to select which robot state you think the robot is in.\n",
    "\n",
    "<span style=\"color:yellow\">**Click on the cell below & hit 'shift + enter'...**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e93b6-816d-4432-a577-9eb5264a9e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "mischelp.get_user_accuracy(sound_obj_array=sound_obj_array_B, lib_str=library_B, sect_str=\"sect3\", user_ID_str=current_user_ID_str, num_of_states=num_of_states, \n",
    "                           states_array=np.ndarray(num_of_states, dtype=object), state_descriptions=state_descriptions, param_disc=param_disc, load_file=sect3_load_str, seed=48)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3993ba-5b58-4ae8-a679-b02ebbbbe714",
   "metadata": {},
   "source": [
    "## Save the Output \n",
    "\n",
    "Run the following code block to save the output of this Jupyter Notebook.\n",
    "\n",
    "<span style=\"color:yellow\">**Click on the cell below & hit 'shift + enter'...**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a7d9c3-6ada-4c30-9b66-f188b63ed069",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_name = \"user_data/user_\" + current_user_ID_str + \"/final_output\"\n",
    "cmd = \"jupyter nbconvert --to webpdf --allow-chromium-download study_notebook_V2.ipynb --output \" + file_path_name\n",
    "if(os.system(cmd)):\n",
    "\tprint(\"Error converting to .py\")\n",
    "\tprint(f\"cmd: {cmd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b267ad4-05ec-4b7a-b79f-bc76eae24fad",
   "metadata": {},
   "source": [
    "## Closing Survey\n",
    "\n",
    "Please click the folliwng link to answer a short post-study questionnaire.\n",
    "\n",
    "<span style=\"color:yellow\">**Pre-study Questionnaire:**</span> https://forms.gle/K6RnncY82vSVdyE38   (Participant ID Required)\n",
    "\n",
    "Thank you for completing this Jupyter Notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945efb78-e5e6-41b1-ba89-25c1fe7b37ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### NOTES & DEBUG\n",
    "\n",
    "<span style=\"color:red\">**This section is not part of the survey.**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e74227-6dca-4d47-b014-88cc9afb0a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PILOTSET ARRAY VALUE SETTER\n",
    "\n",
    "# State 0: Stuck - Pilot Set\n",
    "manual_Qtable_state_0 = np.array([[[1., -1., -3.], [2., 0., -3.], [3., 2., -3.]], \n",
    "\t\t\t\t\t\t\t\t  [[2., -1., -3.], [2., 0., -3.], [4., 2., -3.]],\n",
    "\t\t\t\t\t\t\t\t  [[2., -1., -3.], [3., 0., -3.], [5., 3., -3.]]]) * 1.0\n",
    "\n",
    "print(\"State 0: Stuck\")\n",
    "print(manual_Qtable_state_0.shape, \"\\n\")\n",
    "print(manual_Qtable_state_0, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# State 1: Successful - Pilot Set\n",
    "manual_Qtable_state_1 = np.array([[[-3., 0., 2.], [-3., 1., 3.], [-3., 0., 2.]], \n",
    "\t\t\t\t\t\t\t\t  [[-3., 0., 4.], [-3., 1., 5.], [-3., 0., 3.]],\n",
    "\t\t\t\t\t\t\t\t  [[-3., 0., 2.], [-3., 1., 3.], [-3., 0., 2.]]]) * 1.0\n",
    "\n",
    "print(\"State 1: Successful\")\n",
    "print(manual_Qtable_state_1.shape, \"\\n\")\n",
    "print(manual_Qtable_state_1, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# State 2: Progressing - Pilot Set\n",
    "manual_Qtable_state_2 = np.array([[[0., 3., 0.], [-3., 2., -3.], [-3., 1., -3.]], \n",
    "\t\t\t\t\t\t\t\t  [[0., 5., 0.], [-3., 3., -3.], [-3., 1., -3.]],\n",
    "\t\t\t\t\t\t\t\t  [[0., 4., 0.], [-3., 2., -3.], [-3., 1., -3.]]]) * 1.0\n",
    "\n",
    "print(\"State 2: Successful\")\n",
    "print(manual_Qtable_state_2.shape, \"\\n\")\n",
    "print(manual_Qtable_state_2, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "np.save(\"arrays/pilotset_st0.npy\", manual_Qtable_state_0)\n",
    "np.save(\"arrays/pilotset_st1.npy\", manual_Qtable_state_1)\n",
    "np.save(\"arrays/pilotset_st2.npy\", manual_Qtable_state_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b316ea7-20ff-43e7-8d6d-f167239a42b6",
   "metadata": {},
   "source": [
    "Creating buttons and widgets: https://medium.com/@technologger/how-to-interact-with-jupyter-33a98686f24e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b8dd30-a653-4ac7-9c0b-4009d28ac26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a1b772-d31a-4608-8b21-a740dcf7859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
